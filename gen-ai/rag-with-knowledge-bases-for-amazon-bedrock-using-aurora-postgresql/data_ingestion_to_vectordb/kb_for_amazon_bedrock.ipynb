{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93179240-9c5f-4ba6-a1c7-3a981624f794",
   "metadata": {},
   "source": [
    "# Data Ingestion to Knowledge Base for Amazon Bedrock\n",
    "**_Use of Knowledge Bases for Amazon Bedrock with Amazon Aurora Postgresql using PGVector as a vector database for storing embeddings_**\n",
    "\n",
    "This notebook provides sample code for a data pipeline that ingests documents (typically stored in Amazon S3) into a knowledge base i.e. a vector database such as Amazon Aurora Postgresql using PGVector.\n",
    "\n",
    "This notebook works well with the `Data Science 3.0` kernel on a SageMaker Studio `ml.t3.medium` instance.\n",
    "\n",
    "Here is a list of packages that are used in this notebook.\n",
    "```\n",
    "!pip list | grep -E -w \"boto3|ipython-sql|langchain|langchainhub|psycopg|SQLAlchemy|tenacity\"\n",
    "---------------------------------------------------------------------------------------------\n",
    "boto3                                1.34.127\n",
    "ipython-sql                          0.5.0\n",
    "langchain                            0.2.5\n",
    "langchain-aws                        0.1.6\n",
    "langchain-community                  0.2.4\n",
    "langchain-core                       0.2.7\n",
    "langchainhub                         0.1.20\n",
    "psycopg                              3.1.19\n",
    "psycopg-binary                       3.1.19\n",
    "psycopg-pool                         3.2.2\n",
    "SQLAlchemy                           2.0.28\n",
    "tenacity                             8.2.3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b007828-1c25-4b71-9573-d7cec0417844",
   "metadata": {},
   "source": [
    "# Prerequsites\n",
    "\n",
    "The following IAM policies need to be attached to the SageMaker execution role that you use to run this notebook:\n",
    "\n",
    "- AmazonSageMakerFullAccess\n",
    "- AWSCloudFormationReadOnlyAccess\n",
    "- AmazonS3FullAccess\n",
    "- AmazonRDSReadOnlyAccess\n",
    "- inline policy for Amazon Bedrock\n",
    "  ```\n",
    "  {\n",
    "      \"Version\": \"2012-10-17\",\n",
    "      \"Statement\": [\n",
    "          {\n",
    "              \"Action\": [\n",
    "                  \"bedrock:ListDataSources\",\n",
    "                  \"bedrock:ListFoundationModelAgreementOffers\",\n",
    "                  \"bedrock:ListFoundationModels\",\n",
    "                  \"bedrock:ListIngestionJobs\",\n",
    "                  \"bedrock:ListKnowledgeBases\",\n",
    "                  \"bedrock:ListModelInvocationJobs\"\n",
    "              ],\n",
    "              \"Resource\": \"*\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"BedrockList\"\n",
    "          },\n",
    "          {\n",
    "              \"Action\": [\n",
    "                  \"bedrock:GetDataSource\",\n",
    "                  \"bedrock:GetFoundationModel\",\n",
    "                  \"bedrock:GetFoundationModelAvailability\",\n",
    "                  \"bedrock:GetIngestionJob\",\n",
    "                  \"bedrock:GetKnowledgeBase\",\n",
    "                  \"bedrock:GetModelInvocationJob\",\n",
    "                  \"bedrock:InvokeModel\",\n",
    "                  \"bedrock:InvokeModelWithResponseStream\",\n",
    "                  \"bedrock:ListTagsForResource\",\n",
    "                  \"bedrock:Retrieve\"\n",
    "              ],\n",
    "              \"Resource\": \"*\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"BedrockRead\"\n",
    "          },\n",
    "          {\n",
    "              \"Action\": [\n",
    "                  \"bedrock:CreateFoundationModelAgreement\",\n",
    "                  \"bedrock:CreateModelInvocationJob\",\n",
    "                  \"bedrock:CreateProvisionedModelThroughput\",\n",
    "                  \"bedrock:DeleteFoundationModelAgreement\",\n",
    "                  \"bedrock:DeleteModelInvocationLoggingConfiguration\",\n",
    "                  \"bedrock:DeleteProvisionedModelThroughput\",\n",
    "                  \"bedrock:PutModelInvocationLoggingConfiguration\",\n",
    "                  \"bedrock:RetrieveAndGenerate\",\n",
    "                  \"bedrock:StartIngestionJob\",\n",
    "                  \"bedrock:UpdateDataSource\",\n",
    "                  \"bedrock:UpdateKnowledgeBase\"\n",
    "              ],\n",
    "              \"Resource\": \"*\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"BedrockWrite\"\n",
    "          },\n",
    "          {\n",
    "              \"Action\": [\n",
    "                  \"bedrock:TagResource\",\n",
    "                  \"bedrock:UntagResource\"\n",
    "              ],\n",
    "              \"Resource\": \"*\",\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Sid\": \"BedrockTagging\"\n",
    "          }\n",
    "      ]\n",
    "  }\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f1199-092d-40eb-8a9b-fef0ad619ae3",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aae52c-cd7a-4637-a07d-9c0131dc7d0a",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "Install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e64f84-b7ac-427d-b5a8-cf98b430be9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "!pip install -Uq pip\n",
    "\n",
    "!pip install -U langchain==0.2.5\n",
    "!pip install -U \"boto3>=1.26.159\" langchain-aws==0.1.6\n",
    "!pip install -U langchain-community==0.2.4\n",
    "!pip install -U langchainhub==0.1.20\n",
    "!pip install -U SQLAlchemy==2.0.28\n",
    "!pip install -U tenacity==8.2.3\n",
    "!pip install -U psycopg[binary]==3.1.19\n",
    "!pip install -U ipython-sql==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a8ab9f-fc0e-4866-a981-01288bf33883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list | grep -E -w \"boto3|ipython-sql|langchain|langchainhub|psycopg|SQLAlchemy|tenacity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194877e9-ee48-4a1e-96ee-aa4fdbfa5ca8",
   "metadata": {},
   "source": [
    "## Step 2: Check if Aurora Postgresql is ready to be used as a Knowledge Base for Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ad587-0a05-4db5-804c-384673b4d62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "aws_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e82973-e6f8-461e-8d9b-81e7a5f8fc07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "from utils import (\n",
    "    get_cfn_outputs,\n",
    "    get_secret_name,\n",
    "    get_secret\n",
    ")\n",
    "\n",
    "\n",
    "CFN_STACK_NAME = \"BedrockKBAuroraPgVectorStack\" # name of CloudFormation stack\n",
    "\n",
    "secret_id = get_secret_name(CFN_STACK_NAME)\n",
    "secret = get_secret(secret_id)\n",
    "\n",
    "db_username = secret['username']\n",
    "db_password = urllib.parse.quote_plus(secret['password'])\n",
    "db_port = secret['port']\n",
    "db_host = secret['host']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05692ee4",
   "metadata": {},
   "source": [
    "#### restore variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f3e49-742d-4f07-a3bd-32cfff44fc32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r bedrock_vector_database_name\n",
    "%store -r table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc6331-5972-47fc-8f72-8fb51dac1fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = 'psycopg'\n",
    "connection_string = f\"postgresql+{driver}://{db_username}:{db_password}@{db_host}:{db_port}/{bedrock_vector_database_name}?autocommit=true\"\n",
    "connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849237a-df9f-4899-8dbc-1d925b53e2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4116fc-e993-4c6b-9cd5-82edaf60d652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sql $connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623771bb-452d-41aa-abff-97ea3014c15d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg://postgres:***@rag-pgvector-demo.cluster-cnrh6fettief.us-east-1.rds.amazonaws.com:5432/bedrock_vector_db\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>schemaname</th>\n",
       "            <th>tablename</th>\n",
       "            <th>tableowner</th>\n",
       "            <th>tablespace</th>\n",
       "            <th>hasindexes</th>\n",
       "            <th>hasrules</th>\n",
       "            <th>hastriggers</th>\n",
       "            <th>rowsecurity</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>bedrock_integration</td>\n",
       "            <td>bedrock_kb</td>\n",
       "            <td>bedrock_user</td>\n",
       "            <td>None</td>\n",
       "            <td>True</td>\n",
       "            <td>False</td>\n",
       "            <td>False</td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('bedrock_integration', 'bedrock_kb', 'bedrock_user', None, True, False, False, False)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT *\n",
    "FROM pg_catalog.pg_tables\n",
    "WHERE schemaname != 'pg_catalog' AND\n",
    "    schemaname != 'information_schema';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937657f9-6582-4591-aaac-42c1684b1f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql+psycopg://postgres:***@rag-pgvector-demo.cluster-cnrh6fettief.us-east-1.rds.amazonaws.com:5432/bedrock_vector_db\n",
      "4 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>table_name</th>\n",
       "            <th>column_name</th>\n",
       "            <th>data_type</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>bedrock_kb</td>\n",
       "            <td>id</td>\n",
       "            <td>uuid</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>bedrock_kb</td>\n",
       "            <td>embedding</td>\n",
       "            <td>USER-DEFINED</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>bedrock_kb</td>\n",
       "            <td>metadata</td>\n",
       "            <td>json</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>bedrock_kb</td>\n",
       "            <td>year</td>\n",
       "            <td>integer</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>bedrock_kb</td>\n",
       "            <td>chunks</td>\n",
       "            <td>text</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>bedrock_kb</td>\n",
       "            <td>file_name</td>\n",
       "            <td>character varying</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('bedrock_kb', 'id', 'uuid'),\n",
       " ('bedrock_kb', 'embedding', 'USER-DEFINED'),\n",
       " ('bedrock_kb', 'metadata', 'json'),\n",
       " ('bedrock_kb', 'year', 'integer'),\n",
       " ('bedrock_kb', 'chunks', 'text'),\n",
       " ('bedrock_kb', 'file_name', 'character varying')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT\n",
    "   table_name,\n",
    "   column_name,\n",
    "   data_type\n",
    "FROM\n",
    "   information_schema.columns\n",
    "WHERE\n",
    "   table_name = '{table_name}';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017bc3f-e507-4f0c-b640-ea774c5ea9c8",
   "metadata": {},
   "source": [
    "## Step 3: Download and prepare dataset\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this example, you will use several years of Amazon's Letter to Shareholders as a text corpus to perform Q&A on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752d3a8-2df2-474f-9acb-3a24b3b1be46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "data_root_dir = Path('./data')\n",
    "data_root_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2019-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "]\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root_dir.joinpath(filenames[idx])\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711a949b",
   "metadata": {},
   "source": [
    "### (Optional) Metadata\n",
    "\n",
    "To use the metadata filtering feature, you need to provide metadata files alongside the source data files with the same name as the source data file and `.metadata.json` suffix.\n",
    "\n",
    "For more information, see [here](https://docs.aws.amazon.com/bedrock/latest/userguide/kb-test-config.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668c2367",
   "metadata": {},
   "source": [
    "ℹ️ In PostgreSQL, only `keys` defined as table columns can be added to `metadataAttributes`.\n",
    "\n",
    "In this example, `file_name` and `year` should be in the PostgreSQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for name in filenames:\n",
    "    metadata_file = f\"{name}.metadata.json\"\n",
    "    with open(data_root_dir / metadata_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        content = {\n",
    "            \"metadataAttributes\": {\n",
    "                \"file_name\": name,\n",
    "                \"year\": int(name.split('-')[1])\n",
    "            }\n",
    "        }\n",
    "        content = json.dumps(content)\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2604717-e563-473f-9b78-ccbee2ffb84c",
   "metadata": {},
   "source": [
    "## Step 4: Upload data to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d22e5-fa17-4e59-bbb8-abfbbea528a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFN_STACK_NAME = \"BedrockKnowledgeBaseStack\"\n",
    "cfn_stack_outputs = get_cfn_outputs(CFN_STACK_NAME, aws_region)\n",
    "\n",
    "knowledge_base_id = cfn_stack_outputs['KnowledgeBaseId']\n",
    "data_source_name = cfn_stack_outputs['DataSourceName']\n",
    "\n",
    "knowledge_base_id, data_source_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0699585-94aa-4fdf-a931-e42e5a103d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_agent_client = boto3.client(\n",
    "    'bedrock-agent',\n",
    "    region_name=aws_region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0a6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataSourceId\n",
    "\n",
    "response = bedrock_agent_client.list_data_sources(\n",
    "    knowledgeBaseId=knowledge_base_id\n",
    ")\n",
    "\n",
    "data_source_id = response['dataSourceSummaries'][0]['dataSourceId']\n",
    "data_source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202474f-6fe1-4ffd-9aa9-884a7a9dfd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get DataSource\n",
    "\n",
    "response = bedrock_agent_client.get_data_source(\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    dataSourceId=data_source_id\n",
    ")\n",
    "\n",
    "ds_info = response['dataSource']\n",
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc23a94-9841-4866-96ee-3fc10dd11f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_source_s3_bucket_arn = ds_info['dataSourceConfiguration']['s3Configuration']['bucketArn']\n",
    "data_source_s3_bucket_name = data_source_s3_bucket_arn.split(':')[-1]\n",
    "data_source_s3_bucket_arn, data_source_s3_bucket_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c307586",
   "metadata": {},
   "source": [
    "#### Upload data into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3951301-1c0a-4855-ad56-cfa190448ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "bucket, prefix = data_source_s3_bucket_name, 'data' # Replace prefix with yours\n",
    "\n",
    "dataset_s3_path = S3Uploader.upload(\n",
    "    local_path=str(data_root_dir), desired_s3_uri=f\"s3://{bucket}/{prefix}\"\n",
    ")\n",
    "\n",
    "dataset_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a564de-8a13-4a06-b36c-168e93ab638f",
   "metadata": {},
   "source": [
    "## Step 5: Start ingestion job\n",
    "\n",
    "Once the Knowledge Base and Data Source are created by deploying CDK Stacks, we can start the ingestion job. During the ingestion job, Knowledge Base will fetch the documents in the data source, pre-process it to extract text, chunk it based on the chunking size provided, create embeddings of each chunk and then write it to the vector database, in this case Amazon OpenSearch Serverless Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa943071-4eb1-4710-927b-9ccd73211e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import time\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb15a3-7429-4a92-8e19-54bbe3e8074d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start an ingestion job\n",
    "\n",
    "start_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    dataSourceId=data_source_id\n",
    ")\n",
    "\n",
    "job = start_job_response[\"ingestionJob\"]\n",
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8342290b-8762-46d2-a9a4-e59dca535576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while (job['status'] not in ['COMPLETE', 'FAILED']):\n",
    "    get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "        knowledgeBaseId=knowledge_base_id,\n",
    "        dataSourceId=data_source_id,\n",
    "        ingestionJobId=job[\"ingestionJobId\"]\n",
    "    )\n",
    "\n",
    "    job = get_job_response[\"ingestionJob\"]\n",
    "    if job['status'] not in ['COMPLETE', 'FAILED']:\n",
    "        pp.pprint(job)\n",
    "        time.sleep(30)\n",
    "\n",
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f9006-f49d-4592-9ef4-1ad8a6d54e14",
   "metadata": {},
   "source": [
    "# Test the knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14305c-8de7-4fbe-ac02-ecfac4b5d8d7",
   "metadata": {},
   "source": [
    "## Using Knowlege Bases for Amazon Bedrock APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41719136-d8ff-4cfb-ba09-12d88e702b57",
   "metadata": {},
   "source": [
    "### RetrieveAndGenerate API\n",
    "\n",
    "Behind the scenes, RetrieveAndGenerate API converts queries into embeddings, searches the knowledge base, and then augments the foundation model prompt with the search results as context information and returns the FM-generated response to the question. For multi-turn conversations, Knowledge Bases manage short-term memory of the conversation to provide more contextual results.\n",
    "\n",
    "The output of the RetrieveAndGenerate API includes the generated response, source attribution as well as the retrieved text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba998876-7cb7-4579-a506-d528bcc12648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_agent_runtime_client = boto3.client(\n",
    "    \"bedrock-agent-runtime\",\n",
    "    region_name=aws_region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301dbfeb-a549-4cd2-8dae-5cbd75a82e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "model_arn = f\"arn:aws:bedrock:{aws_region}::foundation-model/{model_id}\"\n",
    "\n",
    "model_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6155a0-509d-403e-80ee-4a213641612b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon is investing heavily in Large Language Models (LLMs) and Generative '\n",
      " 'AI, which it believes will transform and improve virtually every customer '\n",
      " 'experience across its consumer, seller, brand, and creator offerings. Amazon '\n",
      " 'has been working on its own LLMs for a while and sees Generative AI as a '\n",
      " 'technology that will significantly accelerate machine learning adoption. '\n",
      " 'Amazon is democratizing Generative AI technology through AWS, offering '\n",
      " 'price-performant machine learning chips like Trainium and Inferentia so that '\n",
      " 'companies of all sizes can afford to train and run their LLMs in production. '\n",
      " 'AWS also enables companies to choose from various LLMs and build '\n",
      " 'applications with AWS security, privacy and other features. One example is '\n",
      " \"AWS's CodeWhisperer, which uses Generative AI to revolutionize developer \"\n",
      " 'productivity by generating code suggestions in real-time.')\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon's doing in the field of generative AI?\"\n",
    "\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        'text': query\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        'type': 'KNOWLEDGE_BASE',\n",
    "        'knowledgeBaseConfiguration': {\n",
    "            'knowledgeBaseId': knowledge_base_id,\n",
    "            'modelArn': model_arn\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "generated_text = response['output']['text']\n",
    "pp.pprint(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ddebe0-f5c6-4d17-a256-81c1b0c5ba3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'One final investment area that I’ll mention, that’s core to setting Amazon '\n",
      "  'up to invent in every area of our business for many decades to come, and '\n",
      "  'where we’re investing heavily is Large Language Models (“LLMs”) and '\n",
      "  'Generative AI. Machine learning has been a technology with high promise for '\n",
      "  'several decades, but it’s only been the last five to ten years that it’s '\n",
      "  'started to be used more pervasively by companies. This shift was driven by '\n",
      "  'several factors, including access to higher volumes of compute capacity at '\n",
      "  'lower prices than was ever available. Amazon has been using machine '\n",
      "  'learning extensively for 25 years, employing it in everything from '\n",
      "  'personalized ecommerce recommendations, to fulfillment center pick paths, '\n",
      "  'to drones for Prime Air, to Alexa, to the many machine learning services '\n",
      "  'AWS offers (where AWS has the broadest machine learning functionality and '\n",
      "  'customer base of any cloud provider). More recently, a newer form of '\n",
      "  'machine learning, called Generative AI, has burst onto the scene and '\n",
      "  'promises to significantly accelerate machine learning adoption. Generative '\n",
      "  'AI is based on very Large Language Models (trained on up to hundreds of '\n",
      "  'billions of parameters, and growing), across expansive datasets, and has '\n",
      "  'radically general and broad recall and learning capabilities. We have been '\n",
      "  'working on our own LLMs for a while now, believe it will transform and '\n",
      "  'improve virtually every customer experience, and will continue to invest '\n",
      "  'substantially in these models across all of our consumer, seller, brand, '\n",
      "  'and creator experiences. Additionally, as we’ve done for years in AWS, '\n",
      "  'we’re democratizing this technology so companies of all sizes can leverage '\n",
      "  'Generative AI. AWS is offering the most price-performant machine learning '\n",
      "  'chips in Trainium and Inferentia so small and large companies can afford to '\n",
      "  'train and run their LLMs in production. We enable companies to choose from '\n",
      "  'various LLMs and build applications with all of the AWS security, privacy '\n",
      "  'and other features that customers are accustomed to using. And, we’re '\n",
      "  'delivering applications like AWS’s CodeWhisperer, which '\n",
      "  'revolutionizes        developer productivity by generating code suggestions '\n",
      "  'in real time. I could write an entire letter on LLMs and Generative AI as I '\n",
      "  'think they will be that transformative, but I’ll leave that for a future '\n",
      "  'letter. Let’s just say that LLMs and Generative AI are going to be a big '\n",
      "  'deal for customers, our shareholders, and Amazon.   So, in closing, I’m '\n",
      "  'optimistic that we’ll emerge from this challenging macroeconomic time in a '\n",
      "  'stronger position than when we entered it.',\n",
      "  'One final investment area that I’ll mention, that’s core to setting Amazon '\n",
      "  'up to invent in every area of our business for many decades to come, and '\n",
      "  'where we’re investing heavily is Large Language Models (“LLMs”) and '\n",
      "  'Generative AI. Machine learning has been a technology with high promise for '\n",
      "  'several decades, but it’s only been the last five to ten years that it’s '\n",
      "  'started to be used more pervasively by companies. This shift was driven by '\n",
      "  'several factors, including access to higher volumes of compute capacity at '\n",
      "  'lower prices than was ever available. Amazon has been using machine '\n",
      "  'learning extensively for 25 years, employing it in everything from '\n",
      "  'personalized ecommerce recommendations, to fulfillment center pick paths, '\n",
      "  'to drones for Prime Air, to Alexa, to the many machine learning services '\n",
      "  'AWS offers (where AWS has the broadest machine learning functionality and '\n",
      "  'customer base of any cloud provider). More recently, a newer form of '\n",
      "  'machine learning, called Generative AI, has burst onto the scene and '\n",
      "  'promises to significantly accelerate machine learning adoption. Generative '\n",
      "  'AI is based on very Large Language Models (trained on up to hundreds of '\n",
      "  'billions of parameters, and growing), across expansive datasets, and has '\n",
      "  'radically general and broad recall and learning capabilities. We have been '\n",
      "  'working on our own LLMs for a while now, believe it will transform and '\n",
      "  'improve virtually every customer experience, and will continue to invest '\n",
      "  'substantially in these models across all of our consumer, seller, brand, '\n",
      "  'and creator experiences. Additionally, as we’ve done for years in AWS, '\n",
      "  'we’re democratizing this technology so companies of all sizes can leverage '\n",
      "  'Generative AI. AWS is offering the most price-performant machine learning '\n",
      "  'chips in Trainium and Inferentia so small and large companies can afford to '\n",
      "  'train and run their LLMs in production. We enable companies to choose from '\n",
      "  'various LLMs and build applications with all of the AWS security, privacy '\n",
      "  'and other features that customers are accustomed to using. And, we’re '\n",
      "  'delivering applications like AWS’s CodeWhisperer, which '\n",
      "  'revolutionizes        developer productivity by generating code suggestions '\n",
      "  'in real time. I could write an entire letter on LLMs and Generative AI as I '\n",
      "  'think they will be that transformative, but I’ll leave that for a future '\n",
      "  'letter. Let’s just say that LLMs and Generative AI are going to be a big '\n",
      "  'deal for customers, our shareholders, and Amazon.   So, in closing, I’m '\n",
      "  'optimistic that we’ll emerge from this challenging macroeconomic time in a '\n",
      "  'stronger position than when we entered it.']\n"
     ]
    }
   ],
   "source": [
    "## print out the source attribution/citations from the original documents to see if the response generated belongs to the context.\n",
    "\n",
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "        contexts.append(reference[\"content\"][\"text\"])\n",
    "\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec24bf-b591-4148-83b9-bae28a2d83bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Retrieve API\n",
    "\n",
    "Retrieve API converts user queries into embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom workﬂows on top of the semantic search results. The output of the Retrieve API includes the the retrieved text chunks, the location type and URI of the source data, as well as the relevance scores of the retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ba3fd-8043-4e15-89c4-c4c014e01291",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ { 'content': { 'text': 'Amazon Business launched in 2015 and today drives '\n",
      "                         'roughly $35B in annualized gross sales. More than '\n",
      "                         'six million active customers, including 96 of the '\n",
      "                         'global Fortune 100 companies, are enjoying Amazon '\n",
      "                         'Business’ one-stop shopping, real-time analytics, '\n",
      "                         'and broad selection on hundreds of millions of '\n",
      "                         'business supplies. We believe that we’ve only '\n",
      "                         'scratched the surface of what’s possible to date, '\n",
      "                         'and plan to keep building the features our business '\n",
      "                         'customers tell us they need and want.   While many '\n",
      "                         'brands and merchants successfully sell their '\n",
      "                         'products on Amazon’s marketplace, there are also a '\n",
      "                         'large number of brands and sellers who have launched '\n",
      "                         'their own direct-to-consumer websites. One of the '\n",
      "                         'challenges for these merchants is driving conversion '\n",
      "                         'from views to purchases. We invented Buy with Prime '\n",
      "                         'to help with this challenge. Buy with Prime allows '\n",
      "                         'third-party brands and sellers to offer their '\n",
      "                         'products on their own websites to our large Amazon '\n",
      "                         'Prime membership, and offer those customers fast, '\n",
      "                         'free Prime shipping and seamless checkout with their '\n",
      "                         'Amazon account. Buy with Prime provides merchants '\n",
      "                         'several additional benefits, including Amazon '\n",
      "                         'handling the product storage, picking, packing, '\n",
      "                         'delivery, payment, and any returns, all through '\n",
      "                         'Amazon Pay and Fulfillment by Amazon. Buy with Prime '\n",
      "                         'has recently been made available to all US '\n",
      "                         'merchants; and so far, Buy with Prime has increased '\n",
      "                         'shopper conversion on third-party shopping sites by '\n",
      "                         '25% on average. Merchants are excited about '\n",
      "                         'converting more sales and fulfilling these shipments '\n",
      "                         'more easily, Prime members love that they can use '\n",
      "                         'their Prime benefits on more destinations, and Buy '\n",
      "                         'with Prime allows us to improve the shopping '\n",
      "                         'experience across more of the web.   Expanding '\n",
      "                         'internationally, pursuing large retail market '\n",
      "                         'segments that are still nascent for Amazon, and '\n",
      "                         'using our unique assets to help merchants sell more '\n",
      "                         'effectively on their own websites are somewhat '\n",
      "                         'natural extensions for us. There are also a few '\n",
      "                         'investments we’re making that are further from our '\n",
      "                         'core businesses, but where we see unique '\n",
      "                         'opportunity. In 2003, AWS would have been a classic '\n",
      "                         'example. In 2023, Amazon Healthcare and Kuiper are '\n",
      "                         'potential analogues.   Our initial efforts in '\n",
      "                         'Healthcare began with pharmacy, which felt less like '\n",
      "                         'a major departure from ecommerce. For years, Amazon '\n",
      "                         'customers had asked us when we’d offer them an '\n",
      "                         'online pharmacy as their frustrations mounted with '\n",
      "                         'current providers. Launched in 2020, Amazon Pharmacy '\n",
      "                         'is a full-service, online pharmacy that offers '\n",
      "                         'transparent pricing, easy refills, and savings for '\n",
      "                         'Prime members.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.45551138014543324},\n",
      "  { 'content': { 'text': 'We launched our first inference chips (“Inferentia”) '\n",
      "                         'in 2019, and they have saved companies like Amazon '\n",
      "                         'over a hundred million dollars in capital expense '\n",
      "                         'already. Our Inferentia2 chip, which just launched, '\n",
      "                         'offers up to four times higher throughput and ten '\n",
      "                         'times lower latency than our first Inferentia '\n",
      "                         'processor. With the enormous upcoming growth in '\n",
      "                         'machine learning, customers will be able to get a '\n",
      "                         'lot more done with AWS’s training and inference '\n",
      "                         'chips at a significantly lower cost. We’re not close '\n",
      "                         'to being done innovating here, and this long-term '\n",
      "                         'investment should prove fruitful for both customers '\n",
      "                         'and AWS. AWS is still in the early stages of its '\n",
      "                         'evolution, and has a chance for unusual growth in '\n",
      "                         'the next decade.   Similarly high potential, '\n",
      "                         'Amazon’s Advertising business is uniquely effective '\n",
      "                         'for brands, which is part of why it continues to '\n",
      "                         'grow at a brisk clip. Akin to physical retailers’ '\n",
      "                         'advertising businesses selling shelf space, end- '\n",
      "                         'caps, and placement in their circulars, our '\n",
      "                         'sponsored products and brands offerings have been an '\n",
      "                         'integral part        of the Amazon shopping '\n",
      "                         'experience for more than a decade. However, unlike '\n",
      "                         'physical retailers, Amazon can tailor these '\n",
      "                         'sponsored products to be relevant to what customers '\n",
      "                         'are searching for given what we know about shopping '\n",
      "                         'behaviors and our very deep investment in machine '\n",
      "                         'learning algorithms. This leads to advertising '\n",
      "                         'that’s more useful for customers; and as a result, '\n",
      "                         'performs better for brands. This is part of why our '\n",
      "                         'Advertising revenue has continued to grow rapidly '\n",
      "                         '(23% YoY in Q4 2022, 25% YoY overall for 2022 on a '\n",
      "                         '$31B revenue base), even as most large '\n",
      "                         'advertising-focused businesses’ growth have slowed '\n",
      "                         'over the last several quarters.   We strive to be '\n",
      "                         'the best place for advertisers to build their '\n",
      "                         'brands. We have near and long-term opportunities '\n",
      "                         'that will help us achieve that mission. We’re '\n",
      "                         'continuing to make large investments in machine '\n",
      "                         'learning to keep honing our advertising selection '\n",
      "                         'algorithms. For the past couple of years, we’ve '\n",
      "                         'invested in building comprehensive, flexible, and '\n",
      "                         'durable planning and measurement solutions, giving '\n",
      "                         'marketers greater insight into advertising '\n",
      "                         'effectiveness. An example is Amazon Marketing Cloud '\n",
      "                         '(“AMC”). AMC is a “clean room” (i.e. secure digital '\n",
      "                         'environment) in which advertisers can run custom '\n",
      "                         'audience and campaign analytics across a range of '\n",
      "                         'first and third-party inputs, in a privacy-safe '\n",
      "                         'manner, to generate advertising and business '\n",
      "                         'insights to inform their broader marketing and sales '\n",
      "                         'strategies.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.3864634540264107},\n",
      "  { 'content': { 'text': 'One final investment area that I’ll mention, that’s '\n",
      "                         'core to setting Amazon up to invent in every area of '\n",
      "                         'our business for many decades to come, and where '\n",
      "                         'we’re investing heavily is Large Language Models '\n",
      "                         '(“LLMs”) and Generative AI. Machine learning has '\n",
      "                         'been a technology with high promise for several '\n",
      "                         'decades, but it’s only been the last five to ten '\n",
      "                         'years that it’s started to be used more pervasively '\n",
      "                         'by companies. This shift was driven by several '\n",
      "                         'factors, including access to higher volumes of '\n",
      "                         'compute capacity at lower prices than was ever '\n",
      "                         'available. Amazon has been using machine learning '\n",
      "                         'extensively for 25 years, employing it in everything '\n",
      "                         'from personalized ecommerce recommendations, to '\n",
      "                         'fulfillment center pick paths, to drones for Prime '\n",
      "                         'Air, to Alexa, to the many machine learning services '\n",
      "                         'AWS offers (where AWS has the broadest machine '\n",
      "                         'learning functionality and customer base of any '\n",
      "                         'cloud provider). More recently, a newer form of '\n",
      "                         'machine learning, called Generative AI, has burst '\n",
      "                         'onto the scene and promises to significantly '\n",
      "                         'accelerate machine learning adoption. Generative AI '\n",
      "                         'is based on very Large Language Models (trained on '\n",
      "                         'up to hundreds of billions of parameters, and '\n",
      "                         'growing), across expansive datasets, and has '\n",
      "                         'radically general and broad recall and learning '\n",
      "                         'capabilities. We have been working on our own LLMs '\n",
      "                         'for a while now, believe it will transform and '\n",
      "                         'improve virtually every customer experience, and '\n",
      "                         'will continue to invest substantially in these '\n",
      "                         'models across all of our consumer, seller, brand, '\n",
      "                         'and creator experiences. Additionally, as we’ve done '\n",
      "                         'for years in AWS, we’re democratizing this '\n",
      "                         'technology so companies of all sizes can leverage '\n",
      "                         'Generative AI. AWS is offering the most '\n",
      "                         'price-performant machine learning chips in Trainium '\n",
      "                         'and Inferentia so small and large companies can '\n",
      "                         'afford to train and run their LLMs in production. We '\n",
      "                         'enable companies to choose from various LLMs and '\n",
      "                         'build applications with all of the AWS security, '\n",
      "                         'privacy and other features that customers are '\n",
      "                         'accustomed to using. And, we’re delivering '\n",
      "                         'applications like AWS’s CodeWhisperer, which '\n",
      "                         'revolutionizes        developer productivity by '\n",
      "                         'generating code suggestions in real time. I could '\n",
      "                         'write an entire letter on LLMs and Generative AI as '\n",
      "                         'I think they will be that transformative, but I’ll '\n",
      "                         'leave that for a future letter. Let’s just say that '\n",
      "                         'LLMs and Generative AI are going to be a big deal '\n",
      "                         'for customers, our shareholders, and Amazon.   So, '\n",
      "                         'in closing, I’m optimistic that we’ll emerge from '\n",
      "                         'this challenging macroeconomic time in a stronger '\n",
      "                         'position than when we entered it.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.31736001438554395}]\n"
     ]
    }
   ],
   "source": [
    "# retreive api for fetching only the relevant context.\n",
    "\n",
    "relevant_documents = bedrock_agent_runtime_client.retrieve(\n",
    "    retrievalQuery= {\n",
    "        'text': query\n",
    "    },\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    retrievalConfiguration= {\n",
    "        'vectorSearchConfiguration': {\n",
    "            'numberOfResults': 3 # will fetch top 3 documents which matches closely with the query.\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "pp.pprint(relevant_documents[\"retrievalResults\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30493ed4",
   "metadata": {},
   "source": [
    "### (Optional) Metadata filtering\n",
    "\n",
    "With metadata filters, you can retrieve not only semantically relevant chunks but a well-defined subset of those relevant chunks based on applied metadata filters and associated values.\n",
    "\n",
    "For more information, see [here](https://aws.amazon.com/blogs/machine-learning/knowledge-bases-for-amazon-bedrock-now-supports-metadata-filtering-to-improve-retrieval-accuracy/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreive api for fetching only the relevant context with metadata filtering.\n",
    "\n",
    "relevant_documents = bedrock_agent_runtime_client.retrieve(\n",
    "    retrievalQuery= {\n",
    "        'text': query\n",
    "    },\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    retrievalConfiguration= {\n",
    "        'vectorSearchConfiguration': {\n",
    "            'filter': {\n",
    "                'lessThanOrEquals': {\n",
    "                    \"key\": \"year\",\n",
    "                    \"value\": 2020\n",
    "                }\n",
    "            },\n",
    "            'numberOfResults': 3 # will fetch top 3 documents which matches closely with the query.\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "pp.pprint(relevant_documents[\"retrievalResults\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde5a6b-75e9-461b-9f16-f7b9ae3f88c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using LangChain Integration with AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c71329-3b8d-4959-bd69-c6b611496eef",
   "metadata": {},
   "source": [
    "### Using the Knowledge Bases Retriever (AmazonKnowledgeBasesRetriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70986e-ef59-4ab9-8a66-886118fc71ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import AmazonKnowledgeBasesRetriever\n",
    "\n",
    "\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "    knowledge_base_id=knowledge_base_id,\n",
    "    retrieval_config={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\": 3\n",
    "        }\n",
    "    },\n",
    "    region_name=aws_region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66765b81-ac1c-4220-890e-4adea31d29d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Document(page_content='Amazon Business launched in 2015 and today drives roughly $35B in annualized gross sales. More than six million active customers, including 96 of the global Fortune 100 companies, are enjoying Amazon Business’ one-stop shopping, real-time analytics, and broad selection on hundreds of millions of business supplies. We believe that we’ve only scratched the surface of what’s possible to date, and plan to keep building the features our business customers tell us they need and want.   While many brands and merchants successfully sell their products on Amazon’s marketplace, there are also a large number of brands and sellers who have launched their own direct-to-consumer websites. One of the challenges for these merchants is driving conversion from views to purchases. We invented Buy with Prime to help with this challenge. Buy with Prime allows third-party brands and sellers to offer their products on their own websites to our large Amazon Prime membership, and offer those customers fast, free Prime shipping and seamless checkout with their Amazon account. Buy with Prime provides merchants several additional benefits, including Amazon handling the product storage, picking, packing, delivery, payment, and any returns, all through Amazon Pay and Fulfillment by Amazon. Buy with Prime has recently been made available to all US merchants; and so far, Buy with Prime has increased shopper conversion on third-party shopping sites by 25% on average. Merchants are excited about converting more sales and fulfilling these shipments more easily, Prime members love that they can use their Prime benefits on more destinations, and Buy with Prime allows us to improve the shopping experience across more of the web.   Expanding internationally, pursuing large retail market segments that are still nascent for Amazon, and using our unique assets to help merchants sell more effectively on their own websites are somewhat natural extensions for us. There are also a few investments we’re making that are further from our core businesses, but where we see unique opportunity. In 2003, AWS would have been a classic example. In 2023, Amazon Healthcare and Kuiper are potential analogues.   Our initial efforts in Healthcare began with pharmacy, which felt less like a major departure from ecommerce. For years, Amazon customers had asked us when we’d offer them an online pharmacy as their frustrations mounted with current providers. Launched in 2020, Amazon Pharmacy is a full-service, online pharmacy that offers transparent pricing, easy refills, and savings for Prime members.', metadata={'location': {'s3Location': {'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.45050257555619555}),\n",
      "  Document(page_content='We launched our first inference chips (“Inferentia”) in 2019, and they have saved companies like Amazon over a hundred million dollars in capital expense already. Our Inferentia2 chip, which just launched, offers up to four times higher throughput and ten times lower latency than our first Inferentia processor. With the enormous upcoming growth in machine learning, customers will be able to get a lot more done with AWS’s training and inference chips at a significantly lower cost. We’re not close to being done innovating here, and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the early stages of its evolution, and has a chance for unusual growth in the next decade.   Similarly high potential, Amazon’s Advertising business is uniquely effective for brands, which is part of why it continues to grow at a brisk clip. Akin to physical retailers’ advertising businesses selling shelf space, end- caps, and placement in their circulars, our sponsored products and brands offerings have been an integral part        of the Amazon shopping experience for more than a decade. However, unlike physical retailers, Amazon can tailor these sponsored products to be relevant to what customers are searching for given what we know about shopping behaviors and our very deep investment in machine learning algorithms. This leads to advertising that’s more useful for customers; and as a result, performs better for brands. This is part of why our Advertising revenue has continued to grow rapidly (23% YoY in Q4 2022, 25% YoY overall for 2022 on a $31B revenue base), even as most large advertising-focused businesses’ growth have slowed over the last several quarters.   We strive to be the best place for advertisers to build their brands. We have near and long-term opportunities that will help us achieve that mission. We’re continuing to make large investments in machine learning to keep honing our advertising selection algorithms. For the past couple of years, we’ve invested in building comprehensive, flexible, and durable planning and measurement solutions, giving marketers greater insight into advertising effectiveness. An example is Amazon Marketing Cloud (“AMC”). AMC is a “clean room” (i.e. secure digital environment) in which advertisers can run custom audience and campaign analytics across a range of first and third-party inputs, in a privacy-safe manner, to generate advertising and business insights to inform their broader marketing and sales strategies.', metadata={'location': {'s3Location': {'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.388525685651516}),\n",
      "  Document(page_content='One final investment area that I’ll mention, that’s core to setting Amazon up to invent in every area of our business for many decades to come, and where we’re investing heavily is Large Language Models (“LLMs”) and Generative AI. Machine learning has been a technology with high promise for several decades, but it’s only been the last five to ten years that it’s started to be used more pervasively by companies. This shift was driven by several factors, including access to higher volumes of compute capacity at lower prices than was ever available. Amazon has been using machine learning extensively for 25 years, employing it in everything from personalized ecommerce recommendations, to fulfillment center pick paths, to drones for Prime Air, to Alexa, to the many machine learning services AWS offers (where AWS has the broadest machine learning functionality and customer base of any cloud provider). More recently, a newer form of machine learning, called Generative AI, has burst onto the scene and promises to significantly accelerate machine learning adoption. Generative AI is based on very Large Language Models (trained on up to hundreds of billions of parameters, and growing), across expansive datasets, and has radically general and broad recall and learning capabilities. We have been working on our own LLMs for a while now, believe it will transform and improve virtually every customer experience, and will continue to invest substantially in these models across all of our consumer, seller, brand, and creator experiences. Additionally, as we’ve done for years in AWS, we’re democratizing this technology so companies of all sizes can leverage Generative AI. AWS is offering the most price-performant machine learning chips in Trainium and Inferentia so small and large companies can afford to train and run their LLMs in production. We enable companies to choose from various LLMs and build applications with all of the AWS security, privacy and other features that customers are accustomed to using. And, we’re delivering applications like AWS’s CodeWhisperer, which revolutionizes        developer productivity by generating code suggestions in real time. I could write an entire letter on LLMs and Generative AI as I think they will be that transformative, but I’ll leave that for a future letter. Let’s just say that LLMs and Generative AI are going to be a big deal for customers, our shareholders, and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this challenging macroeconomic time in a stronger position than when we entered it.', metadata={'location': {'s3Location': {'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.3117715186183352})]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon doing in the field of Generative AI?\"\n",
    "\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "pp.pprint(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f38cb-3d7b-4200-8135-61e63d9268a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Q&A with RAG using LangChain RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642e57d-a94f-4d4c-90a7-6cff44cb29f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock as BedrockChat\n",
    "\n",
    "\n",
    "llm = BedrockChat(\n",
    "    model_id=model_id,\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589ec5e-0513-4e7f-95aa-039d1bc05c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Human: You are a financial advisor AI system, and provides answers to questions by using fact based and statistical information when possible.\n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "Assistant:\"\"\"\n",
    "claude_prompt = PromptTemplate(template=PROMPT_TEMPLATE,\n",
    "                               input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb862778-e256-4957-90f0-074a8c3c37bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": claude_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba43394-82ea-44cd-a7b2-18df0b3c0e0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'query': 'What is Amazon doing in the field of Generative AI?',\n",
      "  'result': 'According to the context provided, Amazon is investing heavily in '\n",
      "            'Large Language Models (LLMs) and Generative AI. Some key points '\n",
      "            \"about Amazon's efforts in this field:\\n\"\n",
      "            '\\n'\n",
      "            '- Amazon has been working on developing its own LLMs for a while '\n",
      "            'now. LLMs are trained on up to hundreds of billions of parameters '\n",
      "            'across vast datasets.\\n'\n",
      "            '\\n'\n",
      "            '- Amazon believes Generative AI will transform and significantly '\n",
      "            'improve virtually every customer experience across its consumer, '\n",
      "            'seller, brand, and creator offerings. \\n'\n",
      "            '\\n'\n",
      "            '- Amazon is democratizing this technology through AWS so that '\n",
      "            'companies of all sizes can leverage Generative AI. AWS offers '\n",
      "            'machine learning chips like Trainium and Inferentia to enable '\n",
      "            'affordable training and running of LLMs.\\n'\n",
      "            '\\n'\n",
      "            '- AWS provides various pre-trained LLMs that companies can choose '\n",
      "            \"from to build applications, along with AWS's security, privacy \"\n",
      "            'and other features.\\n'\n",
      "            '\\n'\n",
      "            '- AWS has launched applications like CodeWhisperer that use '\n",
      "            'Generative AI to revolutionize developer productivity by '\n",
      "            'generating real-time code suggestions.\\n'\n",
      "            '\\n'\n",
      "            '- The context states that the letter could be entirely written '\n",
      "            'about LLMs and Generative AI, indicating Amazon views it as a '\n",
      "            'highly transformative technology that it is investing '\n",
      "            'substantially in across its businesses.',\n",
      "  'source_documents': [ Document(page_content='Amazon Business launched in 2015 and today drives roughly $35B in annualized gross sales. More than six million active customers, including 96 of the global Fortune 100 companies, are enjoying Amazon Business’ one-stop shopping, real-time analytics, and broad selection on hundreds of millions of business supplies. We believe that we’ve only scratched the surface of what’s possible to date, and plan to keep building the features our business customers tell us they need and want.   While many brands and merchants successfully sell their products on Amazon’s marketplace, there are also a large number of brands and sellers who have launched their own direct-to-consumer websites. One of the challenges for these merchants is driving conversion from views to purchases. We invented Buy with Prime to help with this challenge. Buy with Prime allows third-party brands and sellers to offer their products on their own websites to our large Amazon Prime membership, and offer those customers fast, free Prime shipping and seamless checkout with their Amazon account. Buy with Prime provides merchants several additional benefits, including Amazon handling the product storage, picking, packing, delivery, payment, and any returns, all through Amazon Pay and Fulfillment by Amazon. Buy with Prime has recently been made available to all US merchants; and so far, Buy with Prime has increased shopper conversion on third-party shopping sites by 25% on average. Merchants are excited about converting more sales and fulfilling these shipments more easily, Prime members love that they can use their Prime benefits on more destinations, and Buy with Prime allows us to improve the shopping experience across more of the web.   Expanding internationally, pursuing large retail market segments that are still nascent for Amazon, and using our unique assets to help merchants sell more effectively on their own websites are somewhat natural extensions for us. There are also a few investments we’re making that are further from our core businesses, but where we see unique opportunity. In 2003, AWS would have been a classic example. In 2023, Amazon Healthcare and Kuiper are potential analogues.   Our initial efforts in Healthcare began with pharmacy, which felt less like a major departure from ecommerce. For years, Amazon customers had asked us when we’d offer them an online pharmacy as their frustrations mounted with current providers. Launched in 2020, Amazon Pharmacy is a full-service, online pharmacy that offers transparent pricing, easy refills, and savings for Prime members.', metadata={'location': {'s3Location': {'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.45050257555619555}),\n",
      "                        Document(page_content='We launched our first inference chips (“Inferentia”) in 2019, and they have saved companies like Amazon over a hundred million dollars in capital expense already. Our Inferentia2 chip, which just launched, offers up to four times higher throughput and ten times lower latency than our first Inferentia processor. With the enormous upcoming growth in machine learning, customers will be able to get a lot more done with AWS’s training and inference chips at a significantly lower cost. We’re not close to being done innovating here, and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the early stages of its evolution, and has a chance for unusual growth in the next decade.   Similarly high potential, Amazon’s Advertising business is uniquely effective for brands, which is part of why it continues to grow at a brisk clip. Akin to physical retailers’ advertising businesses selling shelf space, end- caps, and placement in their circulars, our sponsored products and brands offerings have been an integral part        of the Amazon shopping experience for more than a decade. However, unlike physical retailers, Amazon can tailor these sponsored products to be relevant to what customers are searching for given what we know about shopping behaviors and our very deep investment in machine learning algorithms. This leads to advertising that’s more useful for customers; and as a result, performs better for brands. This is part of why our Advertising revenue has continued to grow rapidly (23% YoY in Q4 2022, 25% YoY overall for 2022 on a $31B revenue base), even as most large advertising-focused businesses’ growth have slowed over the last several quarters.   We strive to be the best place for advertisers to build their brands. We have near and long-term opportunities that will help us achieve that mission. We’re continuing to make large investments in machine learning to keep honing our advertising selection algorithms. For the past couple of years, we’ve invested in building comprehensive, flexible, and durable planning and measurement solutions, giving marketers greater insight into advertising effectiveness. An example is Amazon Marketing Cloud (“AMC”). AMC is a “clean room” (i.e. secure digital environment) in which advertisers can run custom audience and campaign analytics across a range of first and third-party inputs, in a privacy-safe manner, to generate advertising and business insights to inform their broader marketing and sales strategies.', metadata={'location': {'s3Location': {'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.388525685651516}),\n",
      "                        Document(page_content='One final investment area that I’ll mention, that’s core to setting Amazon up to invent in every area of our business for many decades to come, and where we’re investing heavily is Large Language Models (“LLMs”) and Generative AI. Machine learning has been a technology with high promise for several decades, but it’s only been the last five to ten years that it’s started to be used more pervasively by companies. This shift was driven by several factors, including access to higher volumes of compute capacity at lower prices than was ever available. Amazon has been using machine learning extensively for 25 years, employing it in everything from personalized ecommerce recommendations, to fulfillment center pick paths, to drones for Prime Air, to Alexa, to the many machine learning services AWS offers (where AWS has the broadest machine learning functionality and customer base of any cloud provider). More recently, a newer form of machine learning, called Generative AI, has burst onto the scene and promises to significantly accelerate machine learning adoption. Generative AI is based on very Large Language Models (trained on up to hundreds of billions of parameters, and growing), across expansive datasets, and has radically general and broad recall and learning capabilities. We have been working on our own LLMs for a while now, believe it will transform and improve virtually every customer experience, and will continue to invest substantially in these models across all of our consumer, seller, brand, and creator experiences. Additionally, as we’ve done for years in AWS, we’re democratizing this technology so companies of all sizes can leverage Generative AI. AWS is offering the most price-performant machine learning chips in Trainium and Inferentia so small and large companies can afford to train and run their LLMs in production. We enable companies to choose from various LLMs and build applications with all of the AWS security, privacy and other features that customers are accustomed to using. And, we’re delivering applications like AWS’s CodeWhisperer, which revolutionizes        developer productivity by generating code suggestions in real time. I could write an entire letter on LLMs and Generative AI as I think they will be that transformative, but I’ll leave that for a future letter. Let’s just say that LLMs and Generative AI are going to be a big deal for customers, our shareholders, and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this challenging macroeconomic time in a stronger position than when we entered it.', metadata={'location': {'s3Location': {'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.3117715186183352})]}\n"
     ]
    }
   ],
   "source": [
    "answer = qa.invoke(query)\n",
    "pp.pprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b9d48-8226-42f7-a59b-2e2c65651a3c",
   "metadata": {},
   "source": [
    "### Q&A with RAG using LCEL (LangChain Expression Language) Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7fb7c-02ff-432a-ac6d-c6ba35871896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import (\n",
    "  create_retrieval_chain\n",
    ")\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, retrieval_qa_chat_prompt)\n",
    "retrieval_qa_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10550e5-7495-4298-8f8a-bc9899e71930",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'answer': 'According to the context, Amazon is investing heavily in large '\n",
      "            'language models (LLMs) and generative AI. Some key points '\n",
      "            'mentioned:\\n'\n",
      "            '\\n'\n",
      "            '1. Amazon believes generative AI based on very large language '\n",
      "            'models will significantly accelerate machine learning adoption '\n",
      "            'and transform virtually every customer experience.\\n'\n",
      "            '\\n'\n",
      "            '2. Amazon has been working on developing its own large language '\n",
      "            'models for a while now.\\n'\n",
      "            '\\n'\n",
      "            '3. Amazon plans to continue investing substantially in these '\n",
      "            'large language models across all of its consumer, seller, brand, '\n",
      "            'and creator experiences.\\n'\n",
      "            '\\n'\n",
      "            '4. Similar to how AWS has democratized other technologies, Amazon '\n",
      "            'is making generative AI available through AWS so that companies '\n",
      "            'of all sizes can leverage it.\\n'\n",
      "            '\\n'\n",
      "            '5. AWS is offering machine learning chips like Trainium and '\n",
      "            'Inferentia to enable affordable training and running of large '\n",
      "            'language models.\\n'\n",
      "            '\\n'\n",
      "            '6. AWS is delivering applications like CodeWhisperer that use '\n",
      "            'generative AI to provide real-time code suggestions, boosting '\n",
      "            'developer productivity.\\n'\n",
      "            '\\n'\n",
      "            '7. The context states that the CEO could write an entire letter '\n",
      "            'on LLMs and generative AI, indicating Amazon views it as a highly '\n",
      "            'transformative technology that it is heavily investing in.',\n",
      "  'context': [ Document(page_content='Amazon Business launched in 2015 and today drives roughly $35B in annualized gross sales. More than six million active customers, including 96 of the global Fortune 100 companies, are enjoying Amazon Business’ one-stop shopping, real-time analytics, and broad selection on hundreds of millions of business supplies. We believe that we’ve only scratched the surface of what’s possible to date, and plan to keep building the features our business customers tell us they need and want.   While many brands and merchants successfully sell their products on Amazon’s marketplace, there are also a large number of brands and sellers who have launched their own direct-to-consumer websites. One of the challenges for these merchants is driving conversion from views to purchases. We invented Buy with Prime to help with this challenge. Buy with Prime allows third-party brands and sellers to offer their products on their own websites to our large Amazon Prime membership, and offer those customers fast, free Prime shipping and seamless checkout with their Amazon account. Buy with Prime provides merchants several additional benefits, including Amazon handling the product storage, picking, packing, delivery, payment, and any returns, all through Amazon Pay and Fulfillment by Amazon. Buy with Prime has recently been made available to all US merchants; and so far, Buy with Prime has increased shopper conversion on third-party shopping sites by 25% on average. Merchants are excited about converting more sales and fulfilling these shipments more easily, Prime members love that they can use their Prime benefits on more destinations, and Buy with Prime allows us to improve the shopping experience across more of the web.   Expanding internationally, pursuing large retail market segments that are still nascent for Amazon, and using our unique assets to help merchants sell more effectively on their own websites are somewhat natural extensions for us. There are also a few investments we’re making that are further from our core businesses, but where we see unique opportunity. In 2003, AWS would have been a classic example. In 2023, Amazon Healthcare and Kuiper are potential analogues.   Our initial efforts in Healthcare began with pharmacy, which felt less like a major departure from ecommerce. For years, Amazon customers had asked us when we’d offer them an online pharmacy as their frustrations mounted with current providers. Launched in 2020, Amazon Pharmacy is a full-service, online pharmacy that offers transparent pricing, easy refills, and savings for Prime members.', metadata={'location': {'s3Location': {'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.45050257555619555}),\n",
      "               Document(page_content='We launched our first inference chips (“Inferentia”) in 2019, and they have saved companies like Amazon over a hundred million dollars in capital expense already. Our Inferentia2 chip, which just launched, offers up to four times higher throughput and ten times lower latency than our first Inferentia processor. With the enormous upcoming growth in machine learning, customers will be able to get a lot more done with AWS’s training and inference chips at a significantly lower cost. We’re not close to being done innovating here, and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the early stages of its evolution, and has a chance for unusual growth in the next decade.   Similarly high potential, Amazon’s Advertising business is uniquely effective for brands, which is part of why it continues to grow at a brisk clip. Akin to physical retailers’ advertising businesses selling shelf space, end- caps, and placement in their circulars, our sponsored products and brands offerings have been an integral part        of the Amazon shopping experience for more than a decade. However, unlike physical retailers, Amazon can tailor these sponsored products to be relevant to what customers are searching for given what we know about shopping behaviors and our very deep investment in machine learning algorithms. This leads to advertising that’s more useful for customers; and as a result, performs better for brands. This is part of why our Advertising revenue has continued to grow rapidly (23% YoY in Q4 2022, 25% YoY overall for 2022 on a $31B revenue base), even as most large advertising-focused businesses’ growth have slowed over the last several quarters.   We strive to be the best place for advertisers to build their brands. We have near and long-term opportunities that will help us achieve that mission. We’re continuing to make large investments in machine learning to keep honing our advertising selection algorithms. For the past couple of years, we’ve invested in building comprehensive, flexible, and durable planning and measurement solutions, giving marketers greater insight into advertising effectiveness. An example is Amazon Marketing Cloud (“AMC”). AMC is a “clean room” (i.e. secure digital environment) in which advertisers can run custom audience and campaign analytics across a range of first and third-party inputs, in a privacy-safe manner, to generate advertising and business insights to inform their broader marketing and sales strategies.', metadata={'location': {'s3Location': {'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.388525685651516}),\n",
      "               Document(page_content='One final investment area that I’ll mention, that’s core to setting Amazon up to invent in every area of our business for many decades to come, and where we’re investing heavily is Large Language Models (“LLMs”) and Generative AI. Machine learning has been a technology with high promise for several decades, but it’s only been the last five to ten years that it’s started to be used more pervasively by companies. This shift was driven by several factors, including access to higher volumes of compute capacity at lower prices than was ever available. Amazon has been using machine learning extensively for 25 years, employing it in everything from personalized ecommerce recommendations, to fulfillment center pick paths, to drones for Prime Air, to Alexa, to the many machine learning services AWS offers (where AWS has the broadest machine learning functionality and customer base of any cloud provider). More recently, a newer form of machine learning, called Generative AI, has burst onto the scene and promises to significantly accelerate machine learning adoption. Generative AI is based on very Large Language Models (trained on up to hundreds of billions of parameters, and growing), across expansive datasets, and has radically general and broad recall and learning capabilities. We have been working on our own LLMs for a while now, believe it will transform and improve virtually every customer experience, and will continue to invest substantially in these models across all of our consumer, seller, brand, and creator experiences. Additionally, as we’ve done for years in AWS, we’re democratizing this technology so companies of all sizes can leverage Generative AI. AWS is offering the most price-performant machine learning chips in Trainium and Inferentia so small and large companies can afford to train and run their LLMs in production. We enable companies to choose from various LLMs and build applications with all of the AWS security, privacy and other features that customers are accustomed to using. And, we’re delivering applications like AWS’s CodeWhisperer, which revolutionizes        developer productivity by generating code suggestions in real time. I could write an entire letter on LLMs and Generative AI as I think they will be that transformative, but I’ll leave that for a future letter. Let’s just say that LLMs and Generative AI are going to be a big deal for customers, our shareholders, and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this challenging macroeconomic time in a stronger position than when we entered it.', metadata={'location': {'s3Location': {'uri': 's3://kb-for-amazon-bedrock-us-east-1-we13viq/data/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'score': 0.3117715186183352})],\n",
      "  'input': 'What is Amazon doing in the field of Generative AI?'}\n"
     ]
    }
   ],
   "source": [
    "answer = retrieval_qa_chain.invoke({'input': query})\n",
    "pp.pprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29eae5-c463-4153-9167-e4628c74d13c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "To avoid incurring future charges, delete the resources. You can do this by deleting the CloudFormation template used to create the IAM role and SageMaker notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce3fe8-bb71-4e22-a551-2475eb2d16b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook we were able to see how to use LLMs provided on Amazon Bedrock to generate embeddings and then ingest those embeddings into Amazon Aurora Postresql and finally do a similarity search for user input to the documents (embeddings) stored in the Aurora Postgresql. We used langchain as an abstraction layer to talk to both Amazon Bedrock as well as a Knowledge Base for Amazon Bedrock with Amazon Aurora Postgresql."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd881bab",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "  * [Amazon Bedrock Knowledge Base - Samples for building RAG workflows](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/knowledge-bases) - This repository contains examples for customers to get started using the Amazon Bedrock Service.\n",
    "  * [(AWS Machine Leearning Blog) Knowledge Bases for Amazon Bedrock now supports metadata filtering to improve retrieval accuracy (2024-04-08)](https://aws.amazon.com/blogs/machine-learning/knowledge-bases-for-amazon-bedrock-now-supports-metadata-filtering-to-improve-retrieval-accuracy/)\n",
    "  * [Build a powerful question answering bot with Amazon SageMaker, Amazon OpenSearch Service, Streamlit, and LangChain](https://aws.amazon.com/blogs/machine-learning/build-a-powerful-question-answering-bot-with-amazon-sagemaker-amazon-opensearch-service-streamlit-and-langchain/)\n",
    "  * [Using the Amazon SageMaker Studio Image Build CLI to build container images from your Studio notebooks](https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/)\n",
    "  * [LangChain](https://python.langchain.com/docs/get_started/introduction.html) - A framework for developing applications powered by language models.\n",
    "  * [LangChain-AWS](https://python.langchain.com/v0.1/docs/integrations/platforms/aws/) - The `LangChain` integrations related to `Amazon AWS` platform.\n",
    "  * [LangChain > Components > Chains](https://python.langchain.com/v0.1/docs/modules/chains/) - Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with [LCEL](https://python.langchain.com/v0.1/docs/expression_language/).\n",
    "  * [LangChain Use cases > Q&A with RAG](https://python.langchain.com/v0.1/docs/use_cases/question_answering/)\n",
    "  * [PostgreSQL Tutorial](https://www.postgresqltutorial.com/)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:123456789012:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
