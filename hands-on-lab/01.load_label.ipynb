{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이번 Lab에서는 Glue Job을 이용해 Database에 접근하고 Read, Write하는 예제를 살펴봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. S3 버킷을 생설할 때 입력한 S3_BUCKET_POSTFIX와 RDS의 HOST, USER, PASSWD 정보를 입력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET_POSTFIX = ''\n",
    "HOST = ''\n",
    "USER = ''\n",
    "PASSWD = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDS_DATABASE = 'hol'\n",
    "RDS_TABLE = 'label'\n",
    "JDBC_URL = 'jdbc:mysql://{HOST}:3306/{DATABASE}'.format(HOST=HOST, DATABASE=RDS_DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Lab을 진행하기 앞서 필요한 Database와 Table을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "conn = pymysql.connect(host=HOST, user=USER, passwd=PASSWD, connect_timeout=5)   \n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        # drop db\n",
    "        query = 'DROP DATABASE IF EXISTS {DATABASE}'.format(DATABASE=RDS_DATABASE)\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # create db\n",
    "        query = 'CREATE DATABASE IF NOT EXISTS {DATABASE}'.format(DATABASE=RDS_DATABASE)\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # create table\n",
    "        query = '''\n",
    "CREATE TABLE IF NOT EXISTS {DATABASE}.{TABLE} (\n",
    "  `passengerid` int(11) NOT NULL,\n",
    "  `label` tinyint(1) DEFAULT NULL\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin\n",
    "        '''.format(DATABASE=RDS_DATABASE, TABLE=RDS_TABLE)\n",
    "        cursor.execute(query)\n",
    "        conn.commit()\n",
    "except Exception as e:\n",
    "    print('[ERROR]: {}'.format(e))\n",
    "    raise\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. JDBC Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from s3\n",
    "s3_bucket = 's3://analytics-hol-' + S3_BUCKET_POSTFIX\n",
    "label_df = spark.read.csv(s3_bucket + '/label', header=True)\n",
    "\n",
    "# wrtie using jdbc\n",
    "connectionProperties = {    \n",
    "    \"user\" : USER,\n",
    "    \"password\" : PASSWD,\n",
    "    \"driver\" : \"com.mysql.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "label_df.write.jdbc(\n",
    "    url=JDBC_URL, \n",
    "    table=RDS_TABLE, \n",
    "    mode=\"overwrite\", \n",
    "    properties=connectionProperties\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. JDBC Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsglue.context import GlueContext\n",
    "\n",
    "# read from jdbc\n",
    "connectionProperties = {\n",
    "    \"user\" : USER,\n",
    "    \"password\" : PASSWD,\n",
    "    \"driver\" : \"com.mysql.jdbc.Driver\",\n",
    "    \"fetchsize\" : \"1000\"\n",
    "}\n",
    "\n",
    "label_df = spark.read.jdbc(\n",
    "        url=JDBC_URL,\n",
    "        table=RDS_TABLE,\n",
    "        properties=connectionProperties)\n",
    "\n",
    "label_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
