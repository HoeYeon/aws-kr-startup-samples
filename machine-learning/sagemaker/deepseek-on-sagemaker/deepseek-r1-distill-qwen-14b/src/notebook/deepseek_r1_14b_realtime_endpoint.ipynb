{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd4c755-a6df-424a-9834-00c193d9dbbb",
   "metadata": {},
   "source": [
    "# Using DeepSeek-R1-Distill-Qwen-14B reasoning model hosted on Amazon SageMaker with DJL Serving DLC\n",
    "\n",
    "\n",
    "❗This notebook works well on `ml.t3.medium` instance with `PyTorch 2.2.0 Python 3.10 CPU optimized` kernel from **SageMaker Studio Classic** or `Python3` kernel from **JupyterLab**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989a5c1-070a-4ac3-b944-085349e904b4",
   "metadata": {},
   "source": [
    "# Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a85b8-c0cb-46bc-b9dc-9f744db4de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "!pip install -U pip\n",
    "!pip install -U \"sagemaker>=2.237.3\"\n",
    "!pip install -U \"transformers>=4.47.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d295f44-fcb8-40fa-b281-f7f817dd971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "aws_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e699e-19f6-41ce-8af7-b29970958e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def get_cfn_outputs(stackname: str, region_name: str='us-east-1') -> List:\n",
    "    cfn = boto3.client('cloudformation', region_name=region_name)\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102fb63a-987c-4e6e-b5c0-9a714ce2765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFN_STACK_NAME = \"DeepSeekR1EndpointStack\"\n",
    "cfn_stack_outputs = get_cfn_outputs(CFN_STACK_NAME, aws_region)\n",
    "\n",
    "endpoint_name = cfn_stack_outputs['EndpointName']\n",
    "model_name = cfn_stack_outputs['ModelName']\n",
    "\n",
    "model_name, endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ca705-0638-4b9a-aa10-b454b1af976d",
   "metadata": {},
   "source": [
    "# Create a Predictor with SageMaker Endpoint name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3ccb7-e069-49f3-a51b-bc458ae3fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99574d3f-1dfb-4773-b08a-7b14797cd7a3",
   "metadata": {},
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7908dbff-b140-4582-bc4a-9b168cce5799",
   "metadata": {},
   "source": [
    "### Message API\n",
    "\n",
    "- Ref: https://docs.djl.ai/docs/serving/serving/docs/lmi/user_guides/chat_input_output_schema.html#message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d51f2-b237-4fa0-b3c8-437b14bf8709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-140334570478352\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1737954736,\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Sure, here is a simple implementation of the Quick Sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    pivot = arr[len(arr) // 2]\\n    left = [x for x in arr if x < pivot]\\n    middle = [x for x in arr if x == pivot]\\n    right = [x for x in arr if x > pivot]\\n    return quick_sort(left) + middle + quick_sort(right)\\n\\nprint(quick_sort([3,6,8,10,1,2,1]))\\n# Output: [1, 1, 2, 3, 6, 8, 10]\\n```\\n\\nThis quick sort implementation uses the divide-and-conquer strategy. It works by choosing a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The sub-arrays are then recursively sorted. This is done until the entire array is sorted.\\n\"\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"eos_token\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 78,\n",
      "    \"completion_tokens\": 252,\n",
      "    \"total_tokens\": 330\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "prompt = \"Help me write a quick sort code in python\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = predictor.predict({\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 5000\n",
    "})\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259fc6c9-5047-4848-a578-5c5d73e24b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, let's generate 10 random numbers using Python programming language.\n",
      "\n",
      "Here's the step-by-step process:\n",
      "\n",
      "1. **Import the random module:** This module provides various functions for generating random numbers.\n",
      "\n",
      "```python\n",
      "import random\n",
      "```\n",
      "\n",
      "2. **Initialize an empty list:** We will use this list to store our random numbers.\n",
      "\n",
      "```python\n",
      "random_numbers = []\n",
      "```\n",
      "\n",
      "3. **Use a loop to generate random numbers:** The `randint()` function in the random module generates a random integer. We will use a loop to generate 10 random integers.\n",
      "\n",
      "```python\n",
      "for i in range(10):\n",
      "    random_numbers.append(random.randint(1, 100))\n",
      "```\n",
      "\n",
      "In the above code, `randint(1, 100)` generates a random integer between 1 and 100. The loop runs 10 times, so it generates 10 random integers.\n",
      "\n",
      "4. **Print the list of random numbers:** Finally, we print the list of random numbers.\n",
      "\n",
      "```python\n",
      "print(random_numbers)\n",
      "```\n",
      "\n",
      "So, the complete code will look like this:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "random_numbers = []\n",
      "\n",
      "for i in range(10):\n",
      "    random_numbers.append(random.randint(1, 100))\n",
      "\n",
      "print(random_numbers)\n",
      "```\n",
      "\n",
      "When you run this code, it will print a list of 10 random integers between 1 and 100.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "prompt = \"Generate 10 random numbers. Please reason step by step.\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = predictor.predict({\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 5000,\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.9,\n",
    "})\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4f822-07ea-4edf-9ee0-9c524f57a4f5",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e90c07-3533-47b9-ba63-bfef63179a83",
   "metadata": {},
   "source": [
    "### Message Schema streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e4204-a815-4645-93f6-699fd1da153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "from sagemaker.iterators import BaseIterator\n",
    "\n",
    "\n",
    "class MessageTokenIterator(BaseIterator):\n",
    "    def __init__(self, stream):\n",
    "        super().__init__(stream)\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line)\n",
    "                full_line = line[:-1].decode('utf-8')\n",
    "                line_data = json.loads(full_line.lstrip('data:').rstrip('\\n'))\n",
    "                return line_data['choices'][0]['delta'].get('content', '')\n",
    "            chunk = next(self.byte_iterator)\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk['PayloadPart']['Bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ae9a0-f624-4580-a10f-ac2d7f043d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a simple Python script that generates 10 random numbers using the random module.\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "random_numbers = []\n",
      "for i in range(10):\n",
      "    random_numbers.append(random.randint(1, 100))\n",
      "\n",
      "print(random_numbers)\n",
      "```\n",
      "\n",
      "This script works as follows:\n",
      "\n",
      "1. The `random` module is imported. This module contains various functions for generating random numbers.\n",
      "\n",
      "2. An empty list `random_numbers` is created to store the generated random numbers.\n",
      "\n",
      "3. A `for` loop is started, which will run 10 times.\n",
      "\n",
      "4. Inside the loop, `random.randint(1, 100)` is called to generate a random integer between 1 and 100 (inclusive). This number is then appended to `random_numbers`.\n",
      "\n",
      "5. After the loop has run 10 times, `random_numbers` will contain 10 random integers between 1 and 100.\n",
      "\n",
      "6. Finally, `random_numbers` is printed to the console.\n",
      "\n",
      "This will print out 10 random numbers between 1 and 100.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Generate 10 random numbers. Please reason step by step.\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 5000,\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.9,\n",
    "    \"stream\": \"true\"\n",
    "}\n",
    "\n",
    "response_stream = predictor.predict_stream(\n",
    "    data=payload,\n",
    "    custom_attributes=\"accept_eula=false\",\n",
    "    iterator=MessageTokenIterator,\n",
    ")\n",
    "\n",
    "for token in response_stream:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c57cc-73a0-4f5d-8c79-b400ea4ac11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등비수열의 항은 다음과 같이 나타낼 수 있습니다:\n",
      "\n",
      "a_n = a_1 * r^n\n",
      "\n",
      "여기서 r은 공비이고, a_1은 첫 번째 항입니다. 주어진 등비수열의 관계식은 다음과 같습니다:\n",
      "\n",
      "(a_4/a_2) + (a_2/a_1) = 30\n",
      "\n",
      "이를 풀면:\n",
      "\n",
      "a_2 * a_2 * a_4 = 30 * a_1 * a_1\n",
      "\n",
      "여기서 a_2와 a_4는 수열의 두 번째와 네 번째 항에 해당하고, a_1은 첫 번째 항에 해당합니다. 따라서, 우리는 다음 식을 얻을 수 있습니다:\n",
      "\n",
      "a_2^2 * a_4 = 30 * a_1^2\n",
      "\n",
      "이 식에서 a_2와 a_4는 양수이므로, a_2^2는 30*a_1^2의 제곱근입니다. 따라서, a_2의 값은 30*a_1^2의 제곱근입니다. 따라서, a_2의 값은 양수이며, 따라서 k의 값은 30*a_1^2의 제곱근입니다.\n",
      "\n",
      "이를 Python 코드로 표현하면 다음과 같습니다:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "# a_1의 값을 제곱근으로 설정\n",
      "a_1 = math.sqrt(30)\n",
      "\n",
      "# a_2의 값을 계산\n",
      "a_2 = math.sqrt(30 * a_1**2)\n",
      "\n",
      "# k의 값을 계산\n",
      "k = a_2\n",
      "\n",
      "print(k)\n",
      "```\n",
      "\n",
      "이 코드는 a_1의 값을 30의 제곱근으로 설정하고, a_2의 값을 30*a_1^2의 제곱근으로 설정하고, k의 값을 a_2로 설정합니다. 그런 다음, k의 값을 출력합니다.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"첫째항과 공비가 모두 양수 k인 등비수열 {a_n}이 (a_4/a_2)+(a_2/a_1)=30을 만족할 때, k의 값은?\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 5000,\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.8,\n",
    "    \"stream\": \"true\"\n",
    "}\n",
    "\n",
    "response_stream = predictor.predict_stream(\n",
    "    data=payload,\n",
    "    custom_attributes=\"accept_eula=false\",\n",
    "    iterator=MessageTokenIterator,\n",
    ")\n",
    "\n",
    "for token in response_stream:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3712ee2-0a8c-42f1-9cad-560bd09785cd",
   "metadata": {},
   "source": [
    "# Clean up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17685ee9-8991-4bb7-a585-3d0c8cf174b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28168876-e166-4572-a482-d60b8a78d0d8",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [DeepSeek-R1 Model Card](https://huggingface.co/deepseek-ai/DeepSeek-R1#usage-recommendations)\n",
    "- [deepseek-ai/deepseek-coder-6.7b-instruct SageMaker LMI deployment guide](https://github.com/aws-samples/llm_deploy_gcr/blob/main/sagemaker/deepseek_coder_6.7_instruct.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
