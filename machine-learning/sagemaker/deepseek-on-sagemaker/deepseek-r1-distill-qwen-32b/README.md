# Hosting DeepSeek R1 on Amazon SageMaker Real-time Inference Endpoint using SageMaker JumpStart

This is a CDK Python project to host [DeepSeek-R1-Distill-Qwen-32B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B) on Amazon SageMaker Real-time Inference Endpoint.

[DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1) is one of the first generation of [DeepSeek](https://www.deepseek.com/) reasoning models, along with [DeepSeek-R1-Zero](https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero).
[DeepSeek-R1-Distill-Qwen-32B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B) is a fine-tuned based on open-source model, using samples generated by DeepSeek-R1.
> :information_source: [DeepSeek-R1 Release](https://api-docs.deepseek.com/news/news250120)

[Amazon Sagemaker JumpStart](https://aws.amazon.com/sagemaker-ai/jumpstart/) is the machine learning (ML) hub of SageMaker that provides access
to foundation models in addition to built-in algorithms and end-to-end solution templates
to help you quickly get started with ML.
You can deploy your model to SageMaker hosting services and get an endpoint that can be used for inference.
These endpoints are fully managed and support autoscaling.

The `cdk.json` file tells the CDK Toolkit how to execute your app.

This project is set up like a standard Python project.  The initialization
process also creates a virtualenv within this project, stored under the `.venv`
directory.  To create the virtualenv it assumes that there is a `python3`
(or `python` for Windows) executable in your path with access to the `venv`
package. If for any reason the automatic creation of the virtualenv fails,
you can create the virtualenv manually.

To manually create a virtualenv on MacOS and Linux:

```
$ git clone --depth=1 https://github.com/aws-samples/aws-kr-startup-samples.git
$ cd aws-kr-startup-samples
$ git sparse-checkout init --cone
$ git sparse-checkout set machine-learning/sagemaker/deepseek-on-sagemaker/deepseek-r1-distill-qwen-32b
$ cd machine-learning/sagemaker/deepseek-on-sagemaker/deepseek-r1-distill-qwen-32b

$ python3 -m venv .venv
```

After the init process completes and the virtualenv is created, you can use the following
step to activate your virtualenv.

```
$ source .venv/bin/activate
```

If you are a Windows platform, you would activate the virtualenv like this:

```
% .venv\Scripts\activate.bat
```

Once the virtualenv is activated, you can install the required dependencies.

```
(.venv) $ pip install -r requirements.txt
```

To add additional dependencies, for example other CDK libraries, just add
them to your `setup.py` file and rerun the `pip install -r requirements.txt`
command.

## Set up `cdk.context.json`

Then, you should set approperly the cdk context configuration file, `cdk.context.json`.

For example,
<pre>
{
  "jumpstart_model_info": {
    "model_id": "deepseek-llm-r1-distill-qwen-32b",
    "version": "1.0.0"
  },
  "sagemaker_endpoint_config": {
    "instance_type": "ml.g6.12xlarge",
    "managed_instance_scaling": {
      "min_instance_count": 1,
      "max_instance_count": 2
    }
  }
}
</pre>

:information_source: The `model_id`, and `version` provided by SageMaker JumpStart can be found in [**SageMaker Built-in Algorithms with pre-trained Model Table**](https://sagemaker.readthedocs.io/en/stable/doc_utils/pretrainedmodels.html).

## Deploy

At this point you can now synthesize the CloudFormation template for this code.

```
(.venv) $ export CDK_DEFAULT_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)
(.venv) $ export CDK_DEFAULT_REGION=$(aws configure get region)
(.venv) $ cdk synth --all
```

Use `cdk deploy` command to create the stack shown above.

```
(.venv) $ cdk deploy --require-approval never --all
```

We can list all the CDK stacks by using the `cdk list` command prior to deployment.

```
(.venv) $ cdk list
```

## Clean Up

Delete the CloudFormation stack by running the below command.

```
(.venv) $ cdk destroy --force --all
```

## Useful commands

 * `cdk ls`          list all stacks in the app
 * `cdk synth`       emits the synthesized CloudFormation template
 * `cdk deploy`      deploy this stack to your default AWS account/region
 * `cdk diff`        compare deployed stack with current state
 * `cdk docs`        open CDK documentation

Enjoy!

## Example

Following [deepseek_r1_32b_realtime_endpoint.ipynb](src/notebook/deepseek_r1_32b_realtime_endpoint.ipynb) on the SageMaker Studio, we can invoke the model with sample data.

## References

 * [(AWS Machine Learning Blog) DeepSeek-R1 model now available in Amazon Bedrock Marketplace and Amazon SageMaker JumpStart (2025-01-30)](https://aws.amazon.com/blogs/machine-learning/deepseek-r1-model-now-available-in-amazon-bedrock-marketplace-and-amazon-sagemaker-jumpstart/)
 * [(AWS Machine Learning Blog) Use Amazon Bedrock tooling with Amazon SageMaker JumpStart models (2024-12-04)](https://aws.amazon.com/blogs/machine-learning/use-amazon-bedrock-tooling-with-amazon-sagemaker-jumpstart-models/)
   * üõ†Ô∏è [sagemaker-genai-hosting-examples/jumpstart-bedrock/amazon-bedrock-with-amazon-sageMaker-jumpstart.ipynb](https://github.com/aws-samples/sagemaker-genai-hosting-examples/blob/main/jumpstart-bedrock/amazon-bedrock-with-amazon-sageMaker-jumpstart.ipynb)
 * [AWS Generative AI CDK Constructs](https://awslabs.github.io/generative-ai-cdk-constructs/)
   * üõ†Ô∏è [awslabs/generative-ai-cdk-constructs](https://github.com/awslabs/generative-ai-cdk-constructs)
 * üõ†Ô∏è [sagemaker-huggingface-inference-toolkit](https://github.com/aws/sagemaker-huggingface-inference-toolkit) - SageMaker Hugging Face Inference Toolkit is an open-source library for serving ü§ó [Transformers](https://huggingface.co/docs/transformers/index) and [Diffusers](https://huggingface.co/docs/diffusers/index) models on Amazon SageMaker.
 * üõ†Ô∏è [sagemaker-inference-toolkit](https://github.com/aws/sagemaker-inference-toolkit) - The SageMaker Inference Toolkit implements a model serving stack and can be easily added to any Docker container, making it [deployable to SageMaker](https://aws.amazon.com/sagemaker/deploy/).
 * üõ†Ô∏è [sagemaker-pytorch-inference-toolkit](https://github.com/aws/sagemaker-pytorch-inference-toolkit) - SageMaker PyTorch Inference Toolkit is an open-source library for serving PyTorch models on Amazon SageMaker.
 * [AWS Generative AI CDK Constructs](https://awslabs.github.io/generative-ai-cdk-constructs/)
 * [SageMaker Built-in Algorithms with pre-trained Model Table](https://sagemaker.readthedocs.io/en/stable/doc_utils/pretrainedmodels.html)
 * [Amazon EC2 Instance types](https://aws.amazon.com/ec2/instance-types/)
