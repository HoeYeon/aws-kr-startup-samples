
# Hosting DeepSeek R1 on Amazon SageMaker Real-time Inference Endpoint using SageMaker JumpStart

This is a CDK Python project to host [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) on Amazon SageMaker Real-time Inference Endpoint.

[DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1) is one of the first generation of [DeepSeek](https://www.deepseek.com/) reasoning models, along with [DeepSeek-R1-Zero](https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero).
[DeepSeek-R1-Distill-Qwen-32B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B) is a fine-tuned based on open-source model, using samples generated by DeepSeek-R1.
> :information_source: [DeepSeek-R1 Release](https://api-docs.deepseek.com/news/news250120)

The `cdk.json` file tells the CDK Toolkit how to execute your app.

This project is set up like a standard Python project.  The initialization
process also creates a virtualenv within this project, stored under the `.venv`
directory.  To create the virtualenv it assumes that there is a `python3`
(or `python` for Windows) executable in your path with access to the `venv`
package. If for any reason the automatic creation of the virtualenv fails,
you can create the virtualenv manually.

To manually create a virtualenv on MacOS and Linux:

```
$ git clone --depth=1 https://github.com/aws-samples/aws-kr-startup-samples.git
$ cd aws-kr-startup-samples
$ git sparse-checkout init --cone
$ git sparse-checkout set machine-learning/sagemaker/deepseek-on-sagemaker/deepseek-r1-distill-llama-8b-sglang
$ cd machine-learning/sagemaker/deepseek-on-sagemaker/deepseek-r1-distill-llama-8b-sglang

$ python3 -m venv .venv
```

After the init process completes and the virtualenv is created, you can use the following
step to activate your virtualenv.

```
$ source .venv/bin/activate
```

If you are a Windows platform, you would activate the virtualenv like this:

```
% .venv\Scripts\activate.bat
```

Once the virtualenv is activated, you can install the required dependencies.

```
(.venv) $ pip install -r requirements.txt
```

To add additional dependencies, for example other CDK libraries, just add
them to your `setup.py` file and rerun the `pip install -r requirements.txt`
command.

## Set up `cdk.context.json`

Then, you should set approperly the cdk context configuration file, `cdk.context.json`.

For example,
<pre>
{
  "ecr": {
    "repository_name": "sglang-sagemaker",
    "tag": "latest"
  },
  "model_id": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
  "model_data_source": {
    "s3_bucket_name": "jumpstart-cache-prod-<i>{region_name}</i>",
    "s3_object_key_name": "deepseek-llm-r1-distill-llama-8b/artifacts/inference-prepack/v1.0.0/"
  },
  "sagemaker_endpoint_settings": {
    "environment": {
      "TENSOR_PARALLEL_DEGREE": "1"
    },
    "min_capacity": 1,
    "max_capacity": 4
  },
  "sagemaker_instance_type": "ml.g5.2xlarge"
}
</pre>

## Deploy

At this point you can now synthesize the CloudFormation template for this code.

```
(.venv) $ export CDK_DEFAULT_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)
(.venv) $ export CDK_DEFAULT_REGION=$(aws configure get region)
(.venv) $ cdk synth --all
```

Use `cdk deploy` command to create the stack shown above.

```
(.venv) $ cdk deploy --require-approval never --all
```

We can list all the CDK stacks by using the `cdk list` command prior to deployment.

```
(.venv) $ cdk list
```

## Clean Up

Delete the CloudFormation stack by running the below command.

```
(.venv) $ cdk destroy --force --all
```

## Useful commands

 * `cdk ls`          list all stacks in the app
 * `cdk synth`       emits the synthesized CloudFormation template
 * `cdk deploy`      deploy this stack to your default AWS account/region
 * `cdk diff`        compare deployed stack with current state
 * `cdk docs`        open CDK documentation

Enjoy!

## (Optional) Deploy the model using SageMaker Python SDK

Following [deploy_deepseek_r1_llama_8b_sglang.ipynb](src/notebook/deploy_deepseek_r1_llama_8b_sglang.ipynb) on the SageMaker Studio, we can deploy the model to Amazon SageMaker.

## Example

Following [deepseek_r1_llama_8b_sglang_realtime_endpoint.ipynb](src/notebook/deepseek_r1_llama_8b_sglang_realtime_endpoint.ipynb) on the SageMaker Studio, we can invoke the model with sample data.

## References

 * [DeepSeek: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://www.deepseek.com/)
   * [DeepSeek in HuggingFace](https://huggingface.co/deepseek-ai)
   * [deepseek-ai/DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)
   * [(GitHub) DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1)
 * üõ†Ô∏è [sagemaker-genai-hosting-examples/Deepseek/SGLang-Deepseek/deepseek-r1-llama-70b-sglang.ipynb](https://github.com/aws-samples/sagemaker-genai-hosting-examples/blob/main/Deepseek/SGLang-Deepseek/deepseek-r1-llama-70b-sglang.ipynb)
 * [AWS Generative AI CDK Constructs](https://awslabs.github.io/generative-ai-cdk-constructs/)
 * [(AWS Blog) Announcing Generative AI CDK Constructs (2024-01-31)](https://aws.amazon.com/blogs/devops/announcing-generative-ai-cdk-constructs/)
 * [Available AWS Deep Learning Containers (DLC) images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)
