# Hosting LLaVA-NeXT-Video model on Amazon SageMaker

This repository contains a set of example CDK Python projects to host the [LLaVA-NeXT-Video](https://llava-vl.github.io/blog/2024-04-30-llava-next-video/)
on Amazon SageMaker Endpoint.

[LLaVA-NeXT-Video](https://huggingface.co/docs/transformers/main/en/model_doc/llava-next-video) is an open-source multimodal LLM trained by fine-tuning LlamA/Vicuna on multimodal instruction-following data generated by Llava1.5 and VideChat.
It is an auto-regressive language model, based on the transformer architecture.
Video-LLaVA unifies visual representations to the language feature space, and enables an LLM to perform visual reasoning capabilities on both images and videos simultaneously.

You can deploy the model to SageMaker hosting services and get an endpoint that can be used for inference. These endpoints are fully managed and support autoscaling.


| Inference Type | Deep Learning Container (DLC) | Example Notebook |
|----------------|-------------------------------|------------------|
| [Asynchronous Inference](./sagemaker-async-inference/) | [PyTorch](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#sagemaker-framework-containers-sm-support-only) | [notebook](./sagemaker-async-inference/src/notebook/llava_next_video_async_endpoint.ipynb) |
| [Real-time Inference](./sagemaker-realtime-inference/) | [PyTorch](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#sagemaker-framework-containers-sm-support-only) | [notebook](./sagemaker-realtime-inference/src/notebook/llava_next_video_realtime_endpoint.ipynb) |

Enjoy!

## References

 * [Amazon SageMaker Deploy models for inference](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)
 * [LLaVA-NeXT-Video](https://llava-vl.github.io/blog/2024-04-30-llava-next-video/): A Strong Zero-shot Video Understanding Model
 * [LLaVA-NeXT-Video-7B-hf Model Card](https://huggingface.co/llava-hf/LLaVA-NeXT-Video-7B-hf)
 * [Available Deep Learning Containers (DLC) images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)

## Related Works

 * [Hosting Video-LLaVA model on Amazon SageMaker Real-time Inference Endpoint](https://github.com/aws-samples/aws-kr-startup-samples/tree/main/machine-learning/sagemaker/video-llava-on-aws-sagemaker)
 * [Hosting LLaVA model on Amazon SageMaker Real-time Inference Endpoint](https://github.com/aws-samples/aws-kr-startup-samples/tree/main/machine-learning/sagemaker/llava-on-aws-sagemaker)
