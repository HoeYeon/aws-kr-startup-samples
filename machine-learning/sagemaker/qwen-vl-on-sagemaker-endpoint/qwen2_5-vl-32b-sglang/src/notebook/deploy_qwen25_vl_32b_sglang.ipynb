{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "042ef63b-53c6-4a06-9472-d67f10e4492a",
   "metadata": {},
   "source": [
    "# Deploy Qwen2.5-VL-32B-Instruct on Amazon SageMaker AI with SGLang\n",
    "\n",
    "❗This notebook works well on `ml.g5.xlarge` instance with 100GB of disk size and `PyTorch 2.2.0 Python 3.10 CPU optimized kernel` from **SageMaker Studio Classic** or `Python3 kernel` from **JupyterLab**.\n",
    "\n",
    "Note that SageMaker provides [pre-built SageMaker AI Docker images](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html) that can help you quickly start with the model inference on SageMaker. It also allows you to [bring your own Docker container](https://docs.aws.amazon.com/sagemaker/latest/dg/adapt-inference-container.html) and use it inside SageMaker AI for training and inference. To be compatible with SageMaker AI, your container must have the following characteristics:\n",
    "\n",
    "- Your container must have a web server listening on port `8080`.\n",
    "- Your container must accept POST requests to the `/invocations` and `/ping` real-time endpoints.\n",
    "\n",
    "In this notebook, we'll demonstrate how to adapt the [SGLang](https://github.com/sgl-project/sglang) framework to run on SageMaker AI endpoints. SGLang is a serving framework for large language models that provides state-of-the-art performance, including a fast backend runtime for efficient serving with RadixAttention, extensive model support, and an active open-source community. For more information refer to [https://docs.sglang.ai/index.html](https://docs.sglang.ai/index.html) and [https://github.com/sgl-project/sglang](https://github.com/sgl-project/sglang).\n",
    "\n",
    "By using SGLang and building a custom Docker container, you can run advanced AI models like the [Qwen2.5-VL-32B-Instruct](https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct)  model on a SageMaker AI endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8e842-d05f-4bce-9257-ab3d0b73b1c6",
   "metadata": {},
   "source": [
    "### Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb5598-17d3-4746-8570-46b4cfa58756",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "!pip install -U pip\n",
    "!pip install -U \"sagemaker>=2.237.3\"\n",
    "!pip install -U huggingface-hub==0.26.2\n",
    "!pip install -U sagemaker-studio-image-build==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df51c59-b524-41bb-a226-2cc95e648285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip freeze | grep -E \"huggingface_hub|sagemaker|torch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02640547-9589-4fa2-8002-91f8f5a41301",
   "metadata": {},
   "source": [
    "### Prepare the SGLang SageMaker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c35792-3164-4740-b2b6-6ba6eef90a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMAGE = 'lmsysorg/sglang:v0.4.4.post3-cu125'\n",
    "DOCKER_IMAGE = \"sglang-sagemaker\"\n",
    "DOCKER_IMAGE_TAG = \"latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b28f7-2d42-4b04-bc0b-200c6d9a0cd1",
   "metadata": {},
   "source": [
    "[sm-docker](https://github.com/aws-samples/sagemaker-studio-image-build-cli) is a CLI for building Docker images in SageMaker Studio using AWS CodeBuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b2da9-ed8d-422d-8c25-0f4d42d77bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!cd ../container && sm-docker build . \\\n",
    "  --repository {DOCKER_IMAGE}:{DOCKER_IMAGE_TAG} \\\n",
    "  --build-arg BASE_IMAGE={BASE_IMAGE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dcad95-7bf0-4f4a-b502-81b81798da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCKER_IMAGE = \"sglang-sagemaker\"\n",
    "DOCKER_IMAGE_TAG = \"latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41634a66-5da5-4003-b924-4ccb8fa34075",
   "metadata": {},
   "source": [
    "### Create SageMaker AI endpoint for EXAONE Deep 7.8B model\n",
    "\n",
    "In this example, we will download the model from HuggingFace and upload to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ebbe8-a37d-47bb-82dc-8039009db275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "model_dir = Path('model')\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-VL-32B-Instruct\"\n",
    "snapshot_download(model_id, local_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953e9ab-ebf0-4d1a-82c8-c6c924ac9339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "region, bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84ec2e-059d-4a46-a0bd-1d84b517e11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"Qwen2.5-VL-32B-Instruct\"\n",
    "\n",
    "base_name = model_name.split('/')[-1].replace('.', '-').lower()\n",
    "base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d9f38-1772-48d2-8e86-a3865e5d1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp model/ s3://{bucket}/{base_name}/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cdeb0-4786-4b3e-951a-e1a425cade91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s3_model_uri = f\"s3://{bucket}/{base_name}/\"\n",
    "s3_model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09f04f-1320-413e-bd3e-7d5745bc7c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "region = session._region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "image_uri = f'{session.account_id()}.dkr.ecr.{region}.amazonaws.com/{DOCKER_IMAGE}:{DOCKER_IMAGE_TAG}'\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832936b1-8aae-46cc-bc81-492bc9d9c43e",
   "metadata": {},
   "source": [
    "Then we will create the [SageMaker model](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html) with the custom docker image and model data available on s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8b4ce-ddc1-493f-8574-310c11188261",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {\n",
    "    \"S3DataSource\": {\n",
    "        \"S3Uri\": s3_model_uri,\n",
    "        \"S3DataType\": \"S3Prefix\",\n",
    "        \"CompressionType\": \"None\",\n",
    "    }\n",
    "}\n",
    "\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfb4e8-1293-4073-a16f-c74be6221174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    env={\n",
    "        'CHAT_TEMPLATE': 'qwen2-vl',\n",
    "        'SM_NUM_GPUS': '4',\n",
    "        # 'TENSOR_PARALLEL_DEGREE': '1', # ml.g5.2xlarge\n",
    "        'TENSOR_PARALLEL_DEGREE': '4' # ml.g5.48xlarge\n",
    "    },\n",
    "    predictor_cls=Predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e888d6d-2bc5-4b6f-9b47-fd22374a02c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "endpoint_name = name_from_base(f'{base_name}-sglang', short=True)\n",
    "instance_type = 'ml.g5.48xlarge' # you can also change to ml.g5.48xlarge or p4d.24xlarge\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51008c65-7ae7-419a-b0de-84650d214cdd",
   "metadata": {},
   "source": [
    "### Invoke endpoint with SageMaker Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8befcb97-418c-4d48-b07a-064f966084fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "The image depicts a serene beach scene with a person and a dog. The person is sitting on the sandy beach, facing the ocean. They are dressed in a plaid shirt and black pants, and they have their legs crossed. The dog, a light-colored breed possibly a Labrador Retriever, is sitting beside them, facing the person. The dog has its paw raised, as if it is giving a paw or pawing at the person's hand. The ocean waves are gently crashing onto the shore, and the sky is clear with a soft, warm light suggesting either sunrise or sunset. The overall atmosphere is calm and peaceful.\n",
       "CPU times: user 3.8 ms, sys: 0 ns, total: 3.8 ms\n",
       "Wall time: 7.29 s\n"
      ]
     }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://github.com/sgl-project/sglang/blob/v0.4.4.post3/python/sglang/srt/conversation.py#L499\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\"\n",
    "                },\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "response = predictor.predict({\n",
    "    'model': 'default',\n",
    "    'messages': messages,\n",
    "    'temperature': 0.6,\n",
    "    'max_new_tokens': 128,\n",
    "    'do_sample': True,\n",
    "    'top_p': 0.95,\n",
    "})\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b5155-64b6-459d-b55b-a5ac149909d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read())\n",
    "        return f\"data:image;base64,{encoded_image.decode('utf-8')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b27084-3ceb-4fb5-8805-80d78f3e240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 개봉선 -\n",
      "자이스 렌즈 와이프 렌즈 표면의 먼지와 얼룩을\n",
      "흔적 없이 부드럽게 닦아주는 일회용 타슈.\n",
      "안전기준 안전확인대상생활화학제품 확인 표시사항\n",
      "제 FB21-02-0531호\n",
      "품목명: 자이스 렌즈 와이프\n",
      "제조자, 제조조국: 프로스베니아이앤씨(Prosbena, Inc.)\n",
      "제조연월: 제품 하단 LOT 번호 앞 네 자리 참조\n",
      "수입자, 주소, 연락처: 칸자이스비진코리아, 중국\n",
      "서울시 송파구 법원로 135, 1201호(02-2252-1001)\n",
      "www.zeiss.com/Cleaning\n",
      "10116-94-004\n",
      "Produced in China\n",
      "CPU times: user 5.85 ms, sys: 227 μs, total: 6.08 ms\n",
      "Wall time: 3.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "base64_image = encode_image_to_base64(\"./examples/image1.png\")\n",
    "\n",
    "# https://github.com/sgl-project/sglang/blob/v0.4.4.post3/python/sglang/srt/conversation.py#L499\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": base64_image\n",
    "                },\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Extract all text from the image and separate each line or text segment with a newline character.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "response = predictor.predict({\n",
    "    'model': 'default',\n",
    "    'messages': messages,\n",
    "    'temperature': 0.6,\n",
    "    'max_new_tokens': 128,\n",
    "    'do_sample': True,\n",
    "    'top_p': 0.95,\n",
    "})\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e053a2-2b8f-49e5-a264-94ef0de57646",
   "metadata": {},
   "source": [
    "### Invoke endpoint with boto3\n",
    "\n",
    "Note that you can also invoke the endpoint with boto3. If you have an existing endpoint, you don't need to recreate the predictor and can follow below example to invoke the endpoint with an endpoint name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a448a5-0cb7-40e2-803b-74cf8c14ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime', region_name=region)\n",
    "endpoint_name = predictor.endpoint_name # you can manually set the endpoint name with an existing endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f00dc-e2ff-4cbb-b144-2843332e3cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a serene beach scene during what appears to be either sunrise or sunset. The sky is a soft gradient of warm colors, transitioning from a light blue at the top to a deeper orange near the horizon. The ocean waves are gently crashing onto the shore, creating small, frothy white foam. \n",
      "\n",
      "On the sandy beach, there is a person and a dog. The person is sitting on the sand, facing the dog, and appears to be interacting with it. The dog, which is likely a Labrador Retriever, is sitting on the sand with its back to the camera, facing the person. The dog's front paws are extended towards the person's hand, suggesting a friendly and playful interaction. The person is wearing a plaid shirt and dark pants, and they have a relaxed posture, indicating a moment of connection with the dog.\n",
      "\n",
      "The overall atmosphere of the image is calm and joyful, capturing a heartwarming moment between a person and their dog at the beach. The lighting and colors contribute to a sense of warmth and tranquility.\n",
      "CPU times: user 13 ms, sys: 104 μs, total: 13.1 ms\n",
      "Wall time: 9.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://github.com/sgl-project/sglang/blob/v0.4.4.post3/python/sglang/srt/conversation.py#L499\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\"\n",
    "                },\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = {\n",
    "    'model': 'default',\n",
    "    'messages': messages,\n",
    "    'temperature': 0.6,\n",
    "    'max_new_tokens': 128,\n",
    "    'do_sample': True,\n",
    "    'top_p': 0.95\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(prompt)\n",
    ")\n",
    "\n",
    "response_dict = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "response_content = response_dict['choices'][0]['message']['content']\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a08611-69e6-4da2-ac4d-ab83c53c7645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 개봉전\n",
      "자이스 렌즈 와이프 렌즈 표면의 먼지와 얼룩을\n",
      "흔적 없이 부드럽게 닦아주는 일회용 타슈.\n",
      "- 안전기준\n",
      "안전확인대상생활화학제품\n",
      "확인\n",
      "표시사항\n",
      "- 신고번호: 제 FB21-02-0531호\n",
      "품목: 제거제\n",
      "제품명: 자이스 렌즈 와이프\n",
      "주요물질: 정제수, 2-프로판올\n",
      "제조연월: 제품 하단 LOT 번호 앞 네 자리 참조\n",
      "제조자, 제조국: 프로스베니아이앤씨(Prosben, Inc.), 중국\n",
      "수입자, 주소, 연락처: 칸자이스비진코리아, 서울시 송파구 법원로 135, 1201호(02-2252-1001)\n",
      "CPU times: user 4.7 ms, sys: 619 μs, total: 5.32 ms\n",
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "base64_image = encode_image_to_base64(\"./examples/image1.png\")\n",
    "\n",
    "# https://github.com/sgl-project/sglang/blob/v0.4.4.post3/python/sglang/srt/conversation.py#L499\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": base64_image\n",
    "                },\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Extract all text from the image and separate each line or text segment with a newline character.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = {\n",
    "    'model': 'default',\n",
    "    'messages': messages,\n",
    "    'temperature': 0.6,\n",
    "    'max_new_tokens': 128,\n",
    "    'do_sample': True,\n",
    "    'top_p': 0.95\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(prompt)\n",
    ")\n",
    "\n",
    "response_dict = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "response_content = response_dict['choices'][0]['message']['content']\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a406aaeb-592e-47fa-849c-c268e95acd40",
   "metadata": {},
   "source": [
    "### Clean up the environment\n",
    "\n",
    "Make sure to delete the endpoint and other artifacts that were created to avoid unnecessary cost. You can also go to SageMaker AI console to delete all the resources created in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9da8c8-0184-4946-b942-b561d5cee2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bacac8b-e78b-4501-811a-f049e98f0a1b",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [Qwen2.5-VL-32B-Instruct Model Card](https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct)\n",
    "- [SGLang Documentation](https://docs.sglang.ai/index.html) - a fast serving framework for large language models and vision language models\n",
    "- [sagemaker-genai-hosting-examples/Deepseek/SGLang-Deepseek/deepseek-r1-llama-70b-sglang.ipynb](https://github.com/aws-samples/sagemaker-genai-hosting-examples/blob/main/Deepseek/SGLang-Deepseek/deepseek-r1-llama-70b-sglang.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
